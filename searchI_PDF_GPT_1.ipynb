{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders.pdf_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFLoader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.document_loaders.pdf_loader'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.pdf_loader import PDFLoader\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. 读取PDF文件并将其内容转换为文本。\n",
    "pdf_loader = PDFLoader()\n",
    "document = pdf_loader.load('/data/IRM_Help.pdf')\n",
    "text = document.get_text()\n",
    "\n",
    "# 2. 将文本切分为小块，确保每块都不超过token的最大长度限制。\n",
    "# 这里我假设你有一个名为tokenize的函数可以进行这个操作\n",
    "tokens = tokenize(text, max_length=512)\n",
    "\n",
    "# 3. 使用embedding模型将文本块转换为向量，并将这些向量存储到向量数据库中。\n",
    "embedder = AzureOpenAIEmbeddings()\n",
    "vectors = [embedder.embed(token) for token in tokens]\n",
    "\n",
    "df = pd.DataFrame({'tokens': tokens, 'embedding_vec': vectors})\n",
    "\n",
    "# 4. 使用Gradio开发用户界面，允许用户输入查询并执行语义搜索。\n",
    "\n",
    "def search_reviews(df, product_description, n=3, pprint=True):\n",
    "    product_embedding = embedder.embed(product_description)\n",
    "    df[\"similarity\"] = df.embedding_vec.apply(lambda x: cosine_similarity([x], [product_embedding])[0][0])\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)\n",
    "        .tokens.str.replace(\"Title: \", \"\")\n",
    "        .str.replace(\"; Content:\", \": \")\n",
    "    )\n",
    "    if pprint:\n",
    "        for r in results:\n",
    "            print(r[:200])\n",
    "            print()\n",
    "    return results\n",
    "\n",
    "iface = gr.Interface(fn=search_reviews, inputs=[\"dataframe\", \"text\"], outputs=\"text\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
